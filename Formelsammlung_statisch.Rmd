---
title: "Formelsammlung Statistik"
author: "Lukas Warode"
output: pdf_document
fontsize: 10pt
---

```{r setup, include=FALSE}
library(tidyverse)

theme_set(theme_classic())

knitr::opts_chunk$set(fig.width = 4, 
                      fig.height = 2.5, 
                      fig.align = "center",
                      cache = FALSE)

modus <- function(var) {
  table(var) %>% 
    sort(decreasing = TRUE) %>% 
    names() %>% 
    .[1] %>% 
    as.numeric()
}
```

# Maße der zentralen Tendenz

## Modus

- Nominales Skalenniveau
- Häufigster Wert

\large 
$$ \large x_{mod} $$ 
\normalsize

## Median

- Ordinales Skalenniveau
- Mittlere Ausprägung bei Anordnung der Variable

Ungerade Anzahl an Fällen (n):
\large
$$ \large \tilde{x} = x_{(\frac{n+1}{2})}$$ 
\normalsize

```{r median I}
set.seed(42)

random_sample <- sample(1:42, 11)

sort(random_sample)

median(random_sample)
```

Gerade Anzahl an Fällen (n):
\large 
$$\large \tilde{x} =\frac{x_{(\frac{n}{2})} + x_{(\frac{n}{2}+1)}}{2}$$
\normalsize

```{r median II}
random_sample <- random_sample[random_sample != max(random_sample)]

sort(random_sample)

median(random_sample)
```

## Arithmetisches Mittel

- Metrisches Skalenniveau
- Summe aller Fälle durch Anzahl der Fälle teilen

\large 
$$\large \bar{x} = \frac{x_{1} + x_{2} + ... + x_{n}}{n} = \frac{1}{n} \sum_{i=i}^{n} x_{i} $$
\normalsize
```{r mean}
random_sample

mean(random_sample)
```

# Verteilungsformen

## Symmetrisch (Normalverteilung)

\large 
$$\large x_{mod} = \tilde{x} = \bar{x} $$
\normalsize
```{r, echo=FALSE, warning=FALSE}
set.seed(42)
random_sample_symmetric <- round(rbeta(1000000, 5, 5), 3)

# random_sample_symmetric <- round(rnorm(n = 10000, mean = 0, sd = 0.5), 1)

# random_sample_symmetric <- round(fGarch::rsnorm(10000, mean = 0, sd = 0.5, xi = -10), 1)

random_sample_symmetric %>% 
  as_tibble() %>% 
  ggplot(aes(value)) + 
  geom_density() +
  geom_vline(xintercept = modus(random_sample_symmetric), alpha = 0.25, linetype = 2) +
  annotate("text", label = expression(x[mod]), x = modus(random_sample_symmetric), y = 1.5, size = 5) +
  # geom_vline(xintercept = median(random_sample_symmetric), alpha = 0.25, linetype = 2) +
  annotate("text", label = expression(tilde(x)) , x = modus(random_sample_symmetric), y = 1, size = 5) +
  # geom_vline(xintercept = mean(random_sample_symmetric), alpha = 0.25, linetype = 2) +
  annotate("text", label = expression(bar(x)), x = modus(random_sample_symmetric), y = 0.5, size = 5) 
```

## Linkssteil / Rechtsschief

\large 
$$\large x_{mod} < \tilde{x} < \bar{x} $$
\normalsize
```{r, echo=FALSE, warning=FALSE}
set.seed(42)
random_sample_right_skewed <- round(rbeta(1000000, 2, 4.5), 3)

# random_sample_right_skewed <- round(rnorm(n = 10000, mean = 0, sd = 0.5), 1)

# random_sample_right_skewed <- round(fGarch::rsnorm(10000, mean = 0, sd = 0.5, xi = -10), 1)

random_sample_right_skewed %>% 
  as_tibble() %>% 
  ggplot(aes(value)) + 
  geom_density() +
  geom_vline(xintercept = modus(random_sample_right_skewed), alpha = 0.25, linetype = 2) +
  annotate("text", label = expression(x[mod]), x = modus(random_sample_right_skewed), y = 1.5, size = 5) +
  geom_vline(xintercept = median(random_sample_right_skewed), alpha = 0.25, linetype = 2) +
  annotate("text", label = expression(tilde(x)), x = median(random_sample_right_skewed), y = 1, size = 5) +
  geom_vline(xintercept = mean(random_sample_right_skewed), alpha = 0.25, linetype = 2) +
  annotate("text", label = expression(bar(x)), x = mean(random_sample_right_skewed), y = 0.5, size = 5) 
```

## Rechtssteil / Linksschief

\large 
$$\large x_{mod} > \tilde{x} > \bar{x} $$
\normalsize
```{r, echo=FALSE, warning=FALSE}
set.seed(42)
random_sample_left_skewed <- round(rbeta(1000000, 4.5, 2), 3)

random_sample_left_skewed %>% 
  as_tibble() %>% 
  ggplot(aes(value)) + 
  geom_density() +
  geom_vline(xintercept = modus(random_sample_left_skewed), alpha = 0.25, linetype = 2) +
  annotate("text", label = expression(x[mod]), x = modus(random_sample_left_skewed), y = 1.5, size = 5) +
  geom_vline(xintercept = median(random_sample_left_skewed), alpha = 0.25, linetype = 2) +
  annotate("text", label = expression(tilde(x)), x = median(random_sample_left_skewed), y = 1, size = 5) +
  geom_vline(xintercept = mean(random_sample_left_skewed), alpha = 0.25, linetype = 2) +
  annotate("text", label = expression(bar(x)), x = mean(random_sample_left_skewed), y = 0.5, size = 5) 
```

# Streuungsmaße

## Spannweite

- Ordinales Skalenniveau
- Differenz zwischen größter und kleinster Ausprägung

\large 
$$\large  R = x_{max} - x_{min} $$
\normalsize

## Interquartilsabstand (IQR)

- Ordinales Skalenniveau
- Intervall der mittleren 50% der Stichprobe

\large 
$$\large  IQR = Q_{0.75} - Q_{0.25} $$
\normalsize

## Variation (Summe der Abweichungsquadrate)

- Metrisches Skalenniveau
- Englisch: *Sum of squares / sum of squared deviations*

\large 
$$\large  SS_{x} = \sum_{i=1}^n (x_{i} - \bar{x})^2 $$
\normalsize

## Varianz 

- Metrisches Skalenniveau
- Standardisierte Variation

\large 
$$\large  s_{x}^2 = \frac{1}{n} \sum_{i=1}^n (x_{i} - \bar{x})^2 $$
\normalsize

## Standardabweichung

- Metrisches Skalenniveau
- Quadratwurzel der Varianz
- Durchschnittliche Abweichung von Werten zum Arithmetischen Mittel

\large 
$$\large  \sigma_{x_{Population}} = \sqrt{\sigma_{x}^2} = \sqrt{\frac{1}{n} \sum_{i=1}^n (x_{i} - \bar{x})^2}$$
$$\large  s_{x_{Stichprobe}} = \sqrt{s_{x}^2} = \sqrt{\frac{1}{n-1} \sum_{i=1}^n (x_{i} - \bar{x})^2} $$
\normalsize

## Variationskoeffizient (Abweichungskoeffizient)

- Metrisches Skalenniveau
- Relatives Streuungsmaß, d.h. nicht abhängig von der Maßeinheit der Variable
- Standardbweichung in Relation zum Arithmetischen Mittel

\large 
$$\large V_{x} = \frac{s_{x}}{\bar{x}} $$
\normalsize

# Standardfehler

- (Durchschnittliche) Abweichung von Stichprobenkennwerten zu Populationskennwerten, z.B. vom Mittelwert

## Standardfehler des Arithmetischen Mittelwertes (*Standard error of the mean*)

- Symbol des Populationsmittelwertes: $\mu$
- Symbol des Stichprobenmittelwertes $\bar{x}$

\large
$$\large \sigma_{\bar{x}_{Population}} = \frac{\sigma}{\sqrt{n}} = \sqrt{\frac{\sigma^2}{n}} $$
$$\large s_{\bar{x}_{Stichprobe}} = \frac{s}{\sqrt{n}} = \sqrt{\frac{s^2}{n}} $$
$$\large \hat{\sigma}_{\bar{x}_{Population, \ geschätzt}} = \frac{s}{\sqrt{n-1}} = \sqrt{\frac{s^2}{n-1}}$$
\normalsize

## Standardfehler des Anteilswertes

- Symbol des Populationsanteilswertes: $\pi$
- Symbol des Stichprobenanteilswertes: $p_{x}$

\large
$$\large \sigma(p_{x})_{Population} = \sqrt{\frac{\pi_{x} \cdot (1-\pi_{x})}{n}} $$
\normalsize

Schätzung der Populationsvarianz: $\pi_{x} \cdot (1-\pi_{x})$ aus der Stichprobenvarianz: $p_{x} \cdot (1-p_{x})$

\large
$$\large \hat{\sigma}(p_{x})_{Population} = \sqrt{\frac{p_{x} \cdot (1-p_{x})}{n}} $$
\normalsize

# Konfidenzintervall

- Generalisierbarkeit von Parametern aus der Stichprobe (auf die Population)
- Geschätzter Intervallbereich, in dem Parameter der Grundgesamtheit mit einer bestimmten Wahrscheinlichkeit liegen

- Z-Standardisierung: $z = \frac{x-\mu}{\sigma}$

## Konfidenzintervall des Populationsmittelwertes ($\mu_{x}$)

- Kleine Stichproben: t-Verteilung
- Große Stichproben: Standardnormalverteilung

Bestimmung der Intervallgrenzen: 

\large
$$\large \bar{x} - \frac{s_{x}}{\sqrt{n-1}} \cdot z_{(1 - \frac{\alpha}{2})} < \mu_{x} < \bar{x} + \frac{s_{x}}{\sqrt{n-1}} \cdot z_{(1 - \frac{\alpha}{2})}$$
\normalsize

## Konfidenzintervall des Populationsanteilswertes ($\pi_{x}$)

- Standardnormalverteilung (wenn Stichprobe ausreichend groß)

Bestimmung der Intervallgrenzen: 

\large
$$\large p_{x} - \sqrt{\frac{p_{x} \cdot (1-p_{x})}{n}} \cdot z_{(1 - \frac{\alpha}{2})} < \pi_{x} < p_{x} + \sqrt{\frac{p_{x} \cdot (1-p_{x})}{n}} \cdot z_{(1 - \frac{\alpha}{2})}$$
\normalsize

# t-Test

## t-Test: Mittelwert

### t-Test für einen Mittelwert

- $H_{0}$: $\mu_{1} = \mu$
- $H_{A}$: $\mu_{1} \neq \mu$

Teststatistik: 

\large
$$\large Z = \frac{\bar{x}-\mu}{\frac{s_{x}}{\sqrt{n-1}}} $$
\normalsize
- Kritische Testwerte bei $z_{\alpha}$ und $z_{(1 -\alpha)}$

### t-Test für 2 Mittelwerte

- $H_{0}$: $\mu_{1} - \mu_{2} = 0$
- $H_{A}$: $\mu_{1} - \mu_{2} \neq 0$

Teststatistik: 

\large
$$\large Z = \frac{\bar{x}_{1} - \bar{x}_{2}}{\sqrt{\frac{s_{x_{1}}^2}{n_{1}-1}-\frac{s_{x_{2}}^2}{n_{2}-1}}} $$
\normalsize
- Kritische Testwerte bei $z_{\frac{\alpha}{2}}$ und $z_{(1 - \frac{\alpha}{2})}$

## t-Test: Populationsanteil

### t-Test für einen Populationsanteil

- $H_{0}$: $\pi_{1} = \pi$
- $H_{A}$: $\pi_{1} \neq \pi$

Teststatistik: 

\large
$$\large Z = \frac{p - \pi}{\sqrt{\frac{\pi \cdot (1-\pi)}{{n}}}}$$
\normalsize
- Kritische Testwerte bei $z_{\alpha}$ und $z_{(1 -\alpha)}$

### t-Test für 2 Populationsanteile

- $H_{0}$: $\pi_{1} - \pi_{2} = 0$
- $H_{A}$: $\pi_{1} - \pi_{2} \neq 0$

Teststatistik: 

\large
$$\large Z = \frac{p_{1} - p_{2}}{\sqrt{\frac{p_1 \cdot (1-p_1)}{n_1} + \frac{p_2 \cdot (1-p_2)}{n_2}}} $$
\normalsize
- Kritische Testwerte bei $z_{\frac{\alpha}{2}}$ und $z_{(1 - \frac{\alpha}{2})}$

# Chi-Quadrat-Unabhängigkeitstest ($\chi^2$)

- Bivariater Test auf stochastische Unabhängigkeit
  - $H_{0}$: Beide Zufallsvariablen sind stochastisch *unabhängig* voneinander
  - $H_{A}$: Beide Zufallsvariablen sind stochastisch *nicht unabhängig* voneinander
  
\large
$$\large \chi^2 = \sum_{i=1}^I \sum_{j=1}^J \frac{(n_{ij} - e_{ij})^2}{e_{ij}} $$
\normalsize

- $i$: *"Zeilen"*
- $j$: *"Spalten"*
- $n_{ij}$: Beobachtete Häufigkeiten
- $e_{ij}$: Erwartete Häufigkeiten
  - $e_{ij} = \frac{n_i \cdot n_j}{n}$
    - $n_i$: Zeilenhäufigkeit
    - $n_j$: Spaltenhäufigkeit
    
Berechnung der Freiheitsgrade (*degrees of freedom*): $df = (I-1) \cdot (J-1)$

## Zusammenhangsmaße auf Basis von $\chi^2$  

\large
$$\large \phi = \sqrt{\frac{\chi^2}{n}} $$
$$\large Cramer`s \ V = \sqrt{\frac{\chi^2}{n \cdot (k-1)}}$$
$$\large Kontingenzkoeffizient \ C =  \sqrt{\frac{\chi^2}{\chi^2 + n}}$$
$$\large C_{korrigiert} = \frac{C}{\sqrt{\frac{k-1}{k}}} $$
\normalsize

- $k = Kleinste \ Zeilenzahl \ oder \ Spaltenzahl$

# F-Test -- Einfaktorielle Varianzanalyse
  
- F-Test testet den Anteil erklärter Varianz an unerklärter Varianz zwischen mehreren Gruppen
- $x_{ij}$:
- $\bar{x}_j$: Mittelwert der Gruppe $j$

- Varianz zwischen den Gruppen: $\sum_{j=1}^p n_j (\bar{x}_j - \bar{x})^2$
  - $df_1: j - 1$

- Varianz innerhalb der Gruppen: $\sum_{j=1}^p \sum_{i=1}^{n_j} (x_{ij} - \bar{x}_j)^2$
  - $df_2: n - j$

Teststatistik:

\large
$$\large F = \frac{erklärte \ Varianz}{unerklärte \ Varianz} = \frac{\frac{Varianz \ zwischen \ den \ Gruppen}{df_1}}{\frac{Varianz \ innerhalb \ der \ Gruppen}{df_2}} = \frac{\frac{\sum_{j=1}^p n_j (\bar{x}_j - \bar{x})^2}{j-1}}{\frac{\sum_{j=1}^p \sum_{i=1}^{n_j} (x_{ij} - \bar{x}_j)^2}{n-j}}$$
\normalsize

# Metrische Zusammenhangsmaße

## Kovarianz

- Kovarianz: Gemeinsame Varianz von 2 Variablen
  - $[-\infty, \ \infty]$
  
\large
$$\large Cov(x,y) = \frac{\sum_{i=1}^n(x_i - \bar{x})(y_i - \bar{y})}{n} = \frac{1}{n} \sum_{i=1}^n(x_i - \bar{x})(y_i - \bar{y})$$
\normalsize

## Korrelation

- Korrelationskoeffizient: Standardisierte Kovarianz
  - $[-1, \ 1]$

\large
$$\large Corr(x,y) = \frac{Cov(x,y)}{\sigma_x \cdot \sigma_y} = \frac{\frac{1}{n} \sum_{i=1}^n(x_i - \bar{x})(y_i - \bar{y})} {\sigma_x \cdot \sigma_y} = \frac{\frac{1}{n}\sum_{i=1}^n(x_i - \bar{x})(y_i - \bar{y})}{\sqrt{\frac{1}{n}\sum_{i=1}^n(x_i - \bar{x})^2 \cdot \frac{1}{n}\sum_{i=1}^n(y_i - \bar{y})^2}}$$
$$\large = \frac{\sum_{i=1}^n(x_i - \bar{x})(y_i - \bar{y})} {\sqrt{\sum_{i=1}^n(x_i - \bar{x})^2 \cdot \sum_{i=1}^n(y_i - \bar{y})^2}}$$
\normalsize
